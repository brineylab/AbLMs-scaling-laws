{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563f3b8-b68b-4e1e-860b-b63e2e0260a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b73136-8f4a-4b44-bb34-cf9dbd587d06",
   "metadata": {},
   "source": [
    "## mutation count annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe1de2-b62d-435b-823b-725abe23d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotated data\n",
    "naive_path = \"/home/jovyan/shared/AbLM_training_data/HDfluJOY_SAHD_naive_AbLM.csv\"\n",
    "mem_path = \"/home/jovyan/shared/AbLM_training_data/HDfluJOY_SAHD_memory_AbLM.csv\"\n",
    "naive = pd.read_csv(naive_path, low_memory=False)\n",
    "memory = pd.read_csv(mem_path, low_memory=False)\n",
    "all_annot = pd.concat([naive, memory], ignore_index=True)\n",
    "\n",
    "# only south african donors\n",
    "all_annot = all_annot[all_annot[\"is_SouthAfrican\"] == True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for relevant columns\n",
    "# [col for col in all_annot.columns]\n",
    "col_list = ['name', 'sample', 'timepoint', 'experiment', 'donor', 'cell_type', \n",
    "            'v_gene:0', 'd_gene:0', 'j_gene:0', 'junction_aa:0', 'cdr3_length:0', 'fr1_aa:0', 'cdr1_aa:0', 'fr2_aa:0', 'cdr2_aa:0', 'fr3_aa:0', 'cdr3_aa:0', 'fr4_aa:0', \n",
    "            'v_identity:0', 'v_identity_aa:0', 'v_mutations:0', 'v_mutations_aa:0', 'v_insertions:0', 'v_deletions:0', 'isotype:0', 'locus:0', 'sequence:0', 'sequence_aa:0',\n",
    "            'v_gene:1', 'd_gene:1', 'j_gene:1', 'junction_aa:1', 'cdr3_length:1', 'fr1_aa:1', 'cdr1_aa:1', 'fr2_aa:1', 'cdr2_aa:1', 'fr3_aa:1', 'cdr3_aa:1', 'fr4_aa:1', \n",
    "            'v_identity:1', 'v_identity_aa:1', 'v_mutations:1', 'v_mutations_aa:1', 'v_insertions:1', 'v_deletions:1', 'isotype:1', 'locus:1', 'sequence:1', 'sequence_aa:1']\n",
    "all_annot = all_annot[col_list]\n",
    "all_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bacc9-9c93-4e47-b90d-3656b433648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count mutations on each chain\n",
    "h = all_annot.loc[:, [\"name\", \"sequence_aa:0\", \"v_identity_aa:0\", \"v_mutations_aa:0\", \"locus:0\"]]\n",
    "h.columns = h.columns.str.replace(':0', '', regex=False)\n",
    "\n",
    "l = all_annot.loc[:, [\"name\", \"sequence_aa:1\", \"v_identity_aa:1\", \"v_mutations_aa:1\", \"locus:1\"]]\n",
    "l.columns = h.columns.str.replace(':0', '', regex=False)\n",
    "\n",
    "all_annot = pd.concat([h, l], ignore_index=True)\n",
    "\n",
    "counts = []\n",
    "for row in all_annot[\"v_mutations_aa\"]:\n",
    "    if isinstance(row, str):\n",
    "        counts.append(row.count(\":\"))\n",
    "    else:\n",
    "        counts.append(0)\n",
    "\n",
    "all_annot[\"v_mutation_count_aa\"] = pd.Series(counts, name=\"v_mutation_count_aa\")\n",
    "all_annot.rename(columns={\"name\":\"sequence_id\"}, inplace=True)\n",
    "all_annot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7081064-9b2c-4439-aaa5-32b8b09197d1",
   "metadata": {},
   "source": [
    "## shuffled pairs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08936a53-d1b8-4e1e-8602-a90abff7ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jovyan/shared/mahdi/1_projects/model_optimization/08paired_classification/data/SA_donors_stuff/all_combined.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b960474-3b4e-4c80-a626-19f0c44b3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate ids for each chain in shuffled dataset \n",
    "df[\"h_id\"] = df[\"name\"].apply(lambda name: name.split(\"|\")[0])\n",
    "df[\"l_id\"] = df[\"name\"].apply(lambda name: name.split(\"|\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718a0e5-9e29-41f8-96b4-153ab074b324",
   "metadata": {},
   "source": [
    "## combine mutation counts and shuffled pairs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d6b4d-f56a-4210-a108-8a05297b0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add mutation counts\n",
    "heavy_all = all_annot[all_annot[\"locus\"] == \"IGH\"]\n",
    "light_all = all_annot[all_annot[\"locus\"] != \"IGH\"]\n",
    "\n",
    "heavy = df.loc[:, [\"name\", \"h_id\", \"h_sequence\", \"label\"]].rename(columns={\"h_id\": \"sequence_id\", \"h_sequence\": \"sequence_aa\"})\n",
    "heavy = heavy.merge(heavy_all, on=[\"sequence_id\", \"sequence_aa\"])\n",
    "heavy = heavy.drop(columns=[\"v_identity_aa\", \"v_mutations_aa\", \"locus\"]).rename(columns={\"sequence_id\":\"h_id\", \"sequence_aa\":\"h_sequence\", \"v_mutation_count_aa\":\"h_mutation_count\"})\n",
    "\n",
    "light = df.loc[:, [\"name\", \"l_id\", \"l_sequence\", \"label\"]].rename(columns={\"l_id\": \"sequence_id\", \"l_sequence\": \"sequence_aa\"})\n",
    "light = light.merge(light_all, on=[\"sequence_id\", \"sequence_aa\"])\n",
    "light = light.drop(columns=[\"v_identity_aa\", \"v_mutations_aa\", \"locus\"]).rename(columns={\"sequence_id\":\"l_id\", \"sequence_aa\":\"l_sequence\", \"v_mutation_count_aa\":\"l_mutation_count\"})\n",
    "\n",
    "data_mut = heavy.merge(light, on=[\"name\", \"label\"]).loc[:, [\"name\", \"label\", \"h_sequence\", \"h_mutation_count\", \"l_sequence\", \"l_mutation_count\"]]\n",
    "data_mut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2f45b-9d4f-432f-a096-3773b88423e7",
   "metadata": {},
   "source": [
    "## process data by mutation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33631dd3-ce4b-4c6c-bdbe-229dd49f1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"8M-Q\", \"35M-Q\", \"150M-Q\", \"350M-Q\", \"650M-Q\", \n",
    "    \"8M-H\", \"35M-H\", \"150M-H\", \"350M-H\", \"650M-H\",\n",
    "    \"8M-F\", \"35M-F\", \"150M-F\", \"350M-F\", \"650M-F\"\n",
    "]\n",
    "\n",
    "# list to load test data with predictions\n",
    "pair_preds = [f\"/home/jovyan/shared/mahdi/1_projects/model_optimization/08paired_classification/SA_donors_ANALYSIS/KN_analysis/results/all_predictions_itr{i}.csv\" for i in range(5)]\n",
    "pair_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd2cfc-fc8a-4ba9-9b99-16c4908dc00c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each iteration, find the predictive accuracies separated by types of chain pairings\n",
    "pairs_types_accs = []\n",
    "for itr in range(len(pair_preds)):\n",
    "\n",
    "    # load data and merge with mutation counts\n",
    "    all_annot = pd.read_csv(pair_preds[itr])\n",
    "    all_annot = all_annot.merge(data_mut, on=[\"name\", \"label\", \"h_sequence\", \"l_sequence\"], how=\"left\")\n",
    "\n",
    "    # different splits of the test dataset based on the mutation count of the chain pairs (both classes)\n",
    "    germline = all_annot[(all_annot[\"h_mutation_count\"] == 0) & (all_annot[\"l_mutation_count\"] == 0)]\n",
    "    mutated = all_annot[(all_annot[\"h_mutation_count\"] != 0) & (all_annot[\"l_mutation_count\"] != 0)]\n",
    "    h_germ = all_annot[(all_annot[\"h_mutation_count\"] == 0) & (all_annot[\"l_mutation_count\"] != 0)]\n",
    "    l_germ = all_annot[(all_annot[\"h_mutation_count\"] != 0) & (all_annot[\"l_mutation_count\"] == 0)]\n",
    "\n",
    "    sames = all_annot[((all_annot[\"h_mutation_count\"] == 0) & (all_annot[\"l_mutation_count\"] == 0)) |\n",
    "                      ((all_annot[\"h_mutation_count\"] != 0) & (all_annot[\"l_mutation_count\"] != 0))]\n",
    "    diffs = all_annot[((all_annot[\"h_mutation_count\"] != 0) & (all_annot[\"l_mutation_count\"] == 0)) |\n",
    "                      ((all_annot[\"h_mutation_count\"] == 0) & (all_annot[\"l_mutation_count\"] != 0))]\n",
    "\n",
    "    datasets = {\n",
    "        \"Unmutated\": germline,\n",
    "        \"Mutated\": mutated,\n",
    "        \"Different\": diffs,\n",
    "        \"All\": all_annot,\n",
    "    }\n",
    "\n",
    "    # calculate stats per sequence type\n",
    "    for model in model_order:\n",
    "        for name, pair_df in datasets.items():\n",
    "            # prediction accuracy\n",
    "            cm = pd.crosstab(pair_df[\"label\"], pair_df[f\"{model}_prediction\"])\n",
    "            pair_acc = np.diag(cm).sum() / cm.to_numpy().sum()\n",
    "            \n",
    "            # mean probability towards CORRECT class\n",
    "            correct_probs = pair_df.apply(lambda p: p[f\"{model}_probability\"] if (p[\"label\"] == 1) else (1 - p[f\"{model}_probability\"]), axis=1)\n",
    "            \n",
    "            pairs_types_accs.append({\n",
    "                \"itr\": itr,\n",
    "                \"model\": model,\n",
    "                \"pair_type\": name,\n",
    "                \"acc\": pair_acc,\n",
    "                \"correct_probability\": correct_probs.mean()\n",
    "            })\n",
    "\n",
    "pair_accs_df = pd.DataFrame(pairs_types_accs)\n",
    "pair_accs_df.groupby([\"pair_type\", \"model\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6388f",
   "metadata": {},
   "source": [
    "## plot overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f2276-d6d3-4190-a43b-1913d4c03d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pair_accs_df[pair_accs_df['pair_type'] == 'All'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34580c21-1dda-4f19-8646-335a92ef5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract model / dataset name\n",
    "all_df[[\"model\", \"datasets\"]] = all_df[\"model\"].str.split(\"-\", 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f1181-ccc4-4157-9195-69d252a9519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pallete = sns.color_palette(\"colorblind\", n_colors=3)\n",
    "palette_dict = {\n",
    "    'F': pallete[0],\n",
    "    'H': pallete[1],\n",
    "    'Q': pallete[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154f044-5f8e-42df-b4d7-ea67128ea764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy barplot\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "sns.barplot(data=all_df,\n",
    "            x=\"model\", y=\"acc\", \n",
    "            hue=\"datasets\", \n",
    "            palette=palette_dict,\n",
    "            errorbar=\"se\",\n",
    "            gap=0.025,\n",
    "            width=0.75,\n",
    "            saturation=0.85,\n",
    "           )\n",
    "\n",
    "# get legends\n",
    "handles_ds, labels_ds = ax.get_legend_handles_labels()\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "# labels & params\n",
    "ax.set_xlabel(\"Model Size (Parameters)\", fontsize=15)\n",
    "ax.set_ylabel(\"Average Accuracy\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize = 12)\n",
    "ax.yaxis.set_tick_params(labelsize = 12)\n",
    "\n",
    "ax.set_ybound(0.48, 0.74)\n",
    "\n",
    "# random guessing line\n",
    "line = plt.axhline(y=0.5, color='black', linestyle='--', label='Random Guessing')\n",
    "ax.legend(handles=[line], loc='upper left', fontsize=12)\n",
    "\n",
    "# plot legend\n",
    "fig.legend(handles_ds, labels_ds, \n",
    "           loc=\"center right\", \n",
    "           title=\"Dataset\",\n",
    "           bbox_to_anchor=(0.99, 0.5),\n",
    "           fontsize=11, title_fontsize=12,\n",
    "           ncols=1)\n",
    "\n",
    "# save\n",
    "plt.savefig(\"./figures/avg_overall_accuracy.pdf\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ada12f-bb4a-484d-8a4e-6df6780aa8e8",
   "metadata": {},
   "source": [
    "## plot true positives / negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081debed-24f0-484e-9623-9ffab4a01930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itr_col(path, itr):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"itr\"] = itr\n",
    "    return df\n",
    "\n",
    "all_pair_preds = [itr_col(pair_preds[itr], itr) for itr in range(len(pair_preds))]\n",
    "all_pair_preds = pd.concat(all_pair_preds, ignore_index=True) \n",
    "len(all_pair_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc950c-9737-4b40-8c4b-a0bc1ac5439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split patterns by model (though i am mostly looking at the overall trend)\n",
    "pred_categories = pd.concat([pd.DataFrame(zip(all_pair_preds[f\"{model}_category\"], \n",
    "                                              all_pair_preds[f\"{model}_probability\"], \n",
    "                                              all_pair_preds[\"itr\"], \n",
    "                                              [model]*len(all_pair_preds)), \n",
    "                                          columns=[\"category\", \"probability\", \"itr\", \"model\"]) for model in model_order])\n",
    "\n",
    "df_truefalse = pred_categories.groupby([\"itr\", \"model\", \"category\"]).size().reset_index(name=\"count\")\n",
    "df_true = df_truefalse[df_truefalse['category'].isin(['true_positive', 'true_negative'])]\n",
    "order = ['350M-Q', '350M-H', '350M-F']\n",
    "palette = {\n",
    "    '350M-F': pallete[0],\n",
    "    '350M-H': pallete[1],\n",
    "    '350M-Q': pallete[2]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.5, 7))\n",
    "sns.barplot(\n",
    "    data=df_true[df_true['model'].isin(order)], \n",
    "    x=\"category\", y=\"count\", hue=\"model\", errorbar=\"se\",\n",
    "    order=[\"true_positive\", \"true_negative\"],\n",
    "    hue_order=order, \n",
    "    palette=palette,\n",
    "    gap=0.025,\n",
    "    width=0.75,\n",
    "    saturation=0.85,\n",
    ")\n",
    "\n",
    "# legend\n",
    "ax.get_legend().set_visible(False)\n",
    "ax.set_title(\"350M Models\", fontsize=15)\n",
    "\n",
    "# x axis\n",
    "ax.set_xlabel(\"Class\", fontsize=15)\n",
    "ax.set_xticklabels([\"Shuffled\", \"Native\"])\n",
    "ax.xaxis.set_tick_params(labelsize = 12)\n",
    "\n",
    "# y axis\n",
    "ax.set_ylabel(\"Number of Correct Predictions\", fontsize=15)\n",
    "ax.yaxis.set_tick_params(labelsize = 12)\n",
    "\n",
    "# save\n",
    "plt.savefig(\"./figures/true-positives-negatives.pdf\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3fec6-9edb-4b22-91dc-2d24915fe92c",
   "metadata": {},
   "source": [
    "## plot heatmaps\n",
    "Accuracy for sequences with 15 or less mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out annotations to just be in the zoomed in area that we are interested in plotting\n",
    "data_mut = data_mut[(data_mut[\"h_mutation_count\"] <= 15) & (data_mut[\"l_mutation_count\"] <= 15)]\n",
    "len(data_mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8b147-e26c-4f60-845a-e362c7c6153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with mutation counts (add mutation counts to inference data)\n",
    "test_data = all_pair_preds.merge(data_mut, on=[\"name\", \"label\", \"h_sequence\", \"l_sequence\"], how=\"inner\")\n",
    "\n",
    "# remove donor, logits, and category columns (for now so that the df is smaller, if i want to use these i can just not remove them)\n",
    "test_data.drop([col_name for col_name in test_data.columns if any(keyword in col_name for keyword in [\"donor\", \"category\", \"logits\"])], axis=1, inplace=True)\n",
    "\n",
    "# stats that cannot be calculated in a groupby object\n",
    "for model in tqdm(model_order):\n",
    "    # correct prediction counter column\n",
    "    test_data[f\"{model}_correct\"] = test_data[\"label\"] == test_data[f\"{model}_prediction\"]\n",
    "\n",
    "    # prediction confidence towards the CORRECT label class\n",
    "    test_data[f\"{model}_confidence_towards_label\"] = test_data.apply(lambda p: p[f\"{model}_probability\"] if (p[\"label\"] == 1) else (1 - p[f\"{model}_probability\"]), axis=1)\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e63a2c-c8fd-42fe-b983-5f9d130ad7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormaps for mutation plots\n",
    "cmap_name = \"RdBu\"\n",
    "cmap = colormaps[cmap_name]\n",
    "cmap_r = colormaps[f\"{cmap_name}_r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febd338-3028-4c1b-aaac-cd8af57f9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate inference stats\n",
    "def agg_stats(grouped_df):\n",
    "    d = {}\n",
    "    # total counts\n",
    "    counts = grouped_df[\"label\"].count()\n",
    "    d[\"count\"] = grouped_df[\"label\"].count()\n",
    "    d[\"log_count\"] = np.log(counts)\n",
    "    d[\"native_count\"] = counts - grouped_df[\"label\"].sum()\n",
    "    d[\"shuffled_count\"] = grouped_df[\"label\"].sum()\n",
    "\n",
    "    # model-specific metrics\n",
    "    for model in model_order:\n",
    "        # accuracy\n",
    "        d[f\"{model}_acc\"] = grouped_df[f\"{model}_correct\"].sum()/counts\n",
    "\n",
    "        # prediction confidence towards CORRECT label (prob if shuffled label [1] , 1-prob if native label [0])\n",
    "        d[f\"{model}_confidence\"] = grouped_df[f\"{model}_confidence_towards_label\"].mean()\n",
    "\n",
    "        # prediction confidence towards shuffled label (probability)\n",
    "        d[f\"{model}_confidence_towards_shuffled\"] = grouped_df[f\"{model}_probability\"].mean()\n",
    "        \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab7625-62f6-4f56-bb3b-9669847572fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by mutation count\n",
    "agg_all = test_data.groupby([\"h_mutation_count\", \"l_mutation_count\"]).apply(agg_stats).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1182c33-0a60-4b44-a0d2-ed97f24420ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_350 = [\"h_mutation_count\", \"l_mutation_count\"] + [col for col in agg_all.columns if '350M' in col]\n",
    "models_350 = [\"350M-Q\", \"350M-H\", \"350M-F\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 5))\n",
    "mappable = None\n",
    "for i, ax in enumerate(axs):\n",
    "    model = models_350[i]\n",
    "\n",
    "    heatmap = sns.heatmap(\n",
    "        agg_all[cols_350].pivot(\n",
    "            index=\"h_mutation_count\", \n",
    "            columns=\"l_mutation_count\", \n",
    "            values=f\"{model}_acc\",\n",
    "        ),\n",
    "        vmin=0, vmax=1,\n",
    "        center=0.5, cmap=cmap_r,\n",
    "        square=True,\n",
    "        ax=ax,\n",
    "        cbar=False\n",
    "    )\n",
    "    if mappable is None:\n",
    "        mappable = heatmap.collections[0] \n",
    "    \n",
    "    ax.set_xlabel(\"Light Chain Mutation Count\", fontsize=14)\n",
    "    ax.set_xticks(np.arange(0.5, 16, 2), \n",
    "                  list(range(0, 16, 2)),\n",
    "                  rotation=\"horizontal\", \n",
    "                  fontsize=10)\n",
    "    \n",
    "    ax.set_ylabel(\"\") \n",
    "    ax.set_yticks(np.arange(0.5, 16, 2), \n",
    "                  list(range(0, 16, 2)),\n",
    "                  rotation=\"horizontal\", \n",
    "                  fontsize=10)\n",
    "    \n",
    "    ax.set_title(f\"{model}\", fontsize=15)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(0.25)\n",
    "        spine.set_color('grey')\n",
    "\n",
    "# shared y axis\n",
    "fig.text(0.09, 0.5, \"Heavy Chain Mutation Count\",\n",
    "         va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# shared colorbar\n",
    "cbar = fig.colorbar(mappable, ax=axs, orientation='vertical', fraction=0.02, pad=0.03, label=\"Average Accuracy\")\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "cbar.outline.set_visible(False)\n",
    "\n",
    "# save\n",
    "plt.savefig(\"./figures/350M_mutation_counts_acc.pdf\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fffd8-d2e1-4374-bf31-0ac4b46b1433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
