{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085ce86c-5c1e-4edb-9820-97d04c7df007",
   "metadata": {},
   "source": [
    "# Pair Classifier Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd187f-cda0-424d-a7b1-5c791ca5ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    EsmTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from datasets import ClassLabel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd5c91-263e-4781-9b57-dcadb602a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009aea9-7326-4391-9fbd-c559781cc16b",
   "metadata": {},
   "source": [
    "## setup model & data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0602ae-3056-4c4b-8087-e65dfe7f680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models and corresponding test data\n",
    "pair_dict = {\n",
    "    n: {\n",
    "        # replace with actual paths to models\n",
    "        \"models\": {\n",
    "            \"8M-Q\":   f\"5fold8M_QUARTER_itr{n}_Paired_class_Final\",\n",
    "            \"8M-H\":   f\"5fold8M_HALF_itr{n}_Paired_class_Final\",\n",
    "            \"8M-F\":   f\"5fold8M_FULL_itr{n}_Paired_class_Final\",\n",
    "            \"35M-Q\":  f\"5fold35M_QUARTER_itr{n}_Paired_class_Final\",\n",
    "            \"35M-H\":  f\"5fold35M_HALF_itr{n}_Paired_class_Final\",\n",
    "            \"35M-F\":  f\"5fold35M_FULL_itr{n}_Paired_class_Final\",\n",
    "            \"150M-Q\": f\"5fold150M_QUARTER_itr{n}_Paired_class_Final\",\n",
    "            \"150M-H\": f\"5fold150M_HALF_itr{n}_Paired_class_Final\",\n",
    "            \"150M-F\": f\"5fold150M_FULL_itr{n}_Paired_class_Final\",\n",
    "            \"350M-Q\": f\"5fold350M_QUARTER_itr{n}_Paired_class_Final\",\n",
    "            \"350M-H\": f\"5fold350M_HALF_itr{n}_Paired_class_Final\",\n",
    "            \"350M-F\": f\"5fold350M_FULL_itr{n}_Paired_class_Final\",\n",
    "            \"650M-Q\": f\"5foldNEW_650M_QUARTER_itr{n}_Paired_class_Final\",\n",
    "            \"650M-H\": f\"5fold650M_HALF_itr{n}_Paired_class_Final\",\n",
    "            \"650M-F\": f\"5fold650M_FULL_itr{n}_Paired_class_Final\",\n",
    "        },\n",
    "        \"data\": f\"../../data/SA_donors_stuff/train-test_splits/native-0_shuffled-1_test{n}.csv\",\n",
    "    }\n",
    "for n in range(5)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73c5ec-4de4-4a0b-b35f-d79c58005b1f",
   "metadata": {},
   "source": [
    "## check that paths exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856fb30-5255-4c47-abff-002bc35cf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_folder_path(start_string, search_dir='.'):\n",
    "    base = Path(search_dir)\n",
    "    for folder in base.iterdir():\n",
    "        if folder.is_dir() and folder.name.startswith(start_string):\n",
    "            return folder.resolve()\n",
    "    raise FileNotFoundError(f\"No folder starting with '{start_string}' found in '{base.resolve()}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a4b37-215a-4f0d-9eed-f46a178d96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pair_dict.keys():\n",
    "    for model_id, model_path in pair_dict[i][\"models\"].items():\n",
    "        folder_path = find_folder_path(model_path, \"../paired_clssification_models/\")\n",
    "        print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6642642-de20-4102-8feb-ad3fd160ecee",
   "metadata": {},
   "source": [
    "## run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2d704-1426-4dc4-b5f5-5e0062d3ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(pair_dict.keys()):\n",
    "\n",
    "    # load test data\n",
    "    test_data = pd.read_csv(pair_dict[i][\"data\"])\n",
    "    test_preds = test_data.copy() # for storing prediction metrics\n",
    "    \n",
    "    class_labels = ClassLabel(names=[\"native-pair\", \"shuffled-pair\"])\n",
    "    n_classes = len(class_labels.names)\n",
    "    label2id = {\"native-pair\": 0, \"shuffled-pair\": 1}\n",
    "    id2label = {0: \"native-pair\", 1: \"shuffled-pair\"}\n",
    "    \n",
    "    # make huggingface dataset\n",
    "    dataset = datasets.Dataset.from_pandas(test_data)\n",
    "    dataset = dataset.cast_column(\"label\", class_labels)\n",
    "    \n",
    "    # filter for length (model has max length of 320 from training)\n",
    "    def filter_long_sequences(item):\n",
    "        return (len(item['h_sequence'])+len(item['l_sequence'])) <= 315 # allows 4 tokens (start, sep (which is 2 tokens long), end)\n",
    "    filtered = dataset.filter(filter_long_sequences)\n",
    "    \n",
    "    # tokenizer\n",
    "    tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\")\n",
    "    \n",
    "    def preprocess_dataset(\n",
    "        batch, \n",
    "        tokenizer=None, \n",
    "        separator=\"<cls><cls>\",\n",
    "        max_len=320\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        docstring\n",
    "        \"\"\"\n",
    "        # tokenize the H/L sequence pair\n",
    "        sequences = [h + separator + l for h, l in zip(batch[\"h_sequence\"], batch[\"l_sequence\"])]\n",
    "        tokenized = tokenizer(sequences, padding=\"max_length\", max_length=max_len)\n",
    "        batch[\"input_ids\"] = tokenized.input_ids\n",
    "        batch[\"attention_mask\"] = tokenized.attention_mask\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    # tokenize\n",
    "    tokenized_dataset = filtered.map(\n",
    "        preprocess_dataset,\n",
    "        fn_kwargs={\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"max_len\": 320,\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=[\"name\", \"h_sequence\", \"l_sequence\", \"donor\"]\n",
    "    )\n",
    "\n",
    "    # load each model\n",
    "    for model_id, model_path_str in pair_dict[i][\"models\"].items():\n",
    "        print(f\"{i}: {model_id}\")\n",
    "        model_path = find_folder_path(model_path_str, \"../paired_clssification_models/\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    \n",
    "        # predict on test set and get metrics\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            args=TrainingArguments(output_dir=\"./\", \n",
    "                                   report_to=\"none\"), # to turn off wandb logging\n",
    "            eval_dataset=tokenized_dataset,\n",
    "        )\n",
    "        logits, labels, metrics = trainer.predict(tokenized_dataset)\n",
    "        probabilities = torch.softmax(torch.from_numpy(logits), dim=1).detach().numpy()[:, -1]\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        \n",
    "        del model # free up memory\n",
    "        \n",
    "        # categorize predictions\n",
    "        pred_data = []\n",
    "        for pred, prob, label, logit in zip(predictions, probabilities, labels, logits):\n",
    "            if pred == label == 1:\n",
    "                category = \"true_positive\"\n",
    "            elif pred == label == 0:\n",
    "                category = \"true_negative\"\n",
    "            elif pred == 1 and label == 0:\n",
    "                category = \"false_positive\"\n",
    "            else:\n",
    "                category = \"false_negative\"\n",
    "            pred_data.append(\n",
    "                {\n",
    "                    # \"label\": label,\n",
    "                    f\"{model_id}_prediction\": pred,\n",
    "                    f\"{model_id}_probability\": prob,\n",
    "                    f\"{model_id}_category\": category,\n",
    "                    f\"{model_id}_logits\": logit,\n",
    "                }\n",
    "            )\n",
    "        pred_df = pd.DataFrame(pred_data)\n",
    "        \n",
    "        # store predictive performance with its corresponding sequence\n",
    "        test_preds = pd.concat([test_preds, pred_df], axis=1)\n",
    "    \n",
    "    # save as csv\n",
    "    save_path = f\"./results/all_predictions_itr{i}.csv\"\n",
    "    print(f\"saving to csv: {save_path} \\n-------------------\\n\\n\")\n",
    "    test_preds.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e5978-292a-4588-8526-d09dabcc7d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
